Gestione della memoria
il sistema operativo svolge il duplice ruolo di : 
        - Gestore delle risorse --> decide quali risorse assegnare ai diversi processi
        - Controllare : assicura che le risorse assegnate ad un altro processo non possano essere usate / alterate dagli altri processi 
le risorse da assegnare ai processi vi é la memoria che dovrebbe 
     1. Ampia 
     2. Veloce
si può avere tutto, perciò si usa una gerarchia di memorie : 
        1. Cache :  memoria di capacità ridotta, molto veloce e costosa
        2. Ram: Memoria di capacitò dell'ordine di alcuni GB, velocità media e prezzo medio
        3. Dischi : centiania di GB di memoria ad alta capacitò, più lenta ed economica.

e |                                                         ^ e
t |                                                         | t 
n |                                                         | n
e |                                                         | e 
c |                                                         | c 
s |                                                         | s 
e |                                                         | e 
r |                                                         | r 
c |                                                         | c
  |                                                         | 
à |                                                         | a
t |                          Registrers                     | t
i |                            Cache                        | i
c |                          Main Memory                    | c
a |                         Magnetic disck                  | o   
p |                         Magnetic Tape                   | l   
a |                                                         | E
c >                                                         | V

la gerarchia della memoria consiste nel portare verso il vertice della piramide le informazioni più usate dalle prozioni di programma in esecuzione
la maggior parte dei casi il tempo di accesso coincide con quello delle memorie più rapide.

l'aggiornaemnto del contenuto della cache è gestito per lo più in hardware. se l'hit rate é alto, si ha un tempo medio di accesso alla memoria intermedio 
tra quello della RAM e quello della cache

Indirizzi logici e fisici 
allocare liberamente i processi in memoria (RAM) occorre distinguere tra indirizzi logici e indirizzi fisici, il binding (Associazione), tra indirizzi logici
e indirizzi fisici può avvenire in momenti diversi : 
la compilazione, durante il caricamento oppure run-time, il più flessibile, in questo caso nel file eseguibile c'è un indirizzo. é un indirizzo logico e una volta caricato il programma
in RAM, gli indirizzi degli operandi, delle istruzioni, i valori delle variabili puntatore, tutti gli indirizzi generati dal programma sono indirizzi logici.

MMU (Memory Management UNIT) si occupa di operare la traduzione al momento dell'accesso in memoria (da logico a fisico).

Rilocabilità e protezione dei sistemi multiprogrammati
- Allocazione contigua dell'immagine del processo
- Un registro base e registro limite

LA MMU svolge in hardawre la funzione  :
 if (base + ind_logico >Limite) then
    trap("Segmentation Fault")
  else ind_fisico = Base + ind_gioco

oltre alla traduzione logico-fisico permette di confinare un prorcesso allo spazio ad esso assegnato garantendo cosi la protezione del sistema operativo e degli altri processi.

i registri limit e base possono essere modificati solo in modo kernel, la traduzione indirizzo logico_indirizzo fisico e il controllo di non superamento dei limiti viene fatta dalla MMU
il valore base e limite di ogni processo sono memorizzati nel PCB.

Allocazione spazio in memoria : partizioni fisse
Gestione dello spazio in RAM  nei registri multiprorgrammati: i job sottoposti al sistema sono caricati su disco; se ne tiene traccia in una cosa, caricandoli in memoria quando si libera una partizione,
la suddivisione in partizioni é configurata dal sistema all'avvio del sistema.
le code possono essere separate per partizioni o congiunte.
possiamo trovare uno spreco di memoria, in particolare Frammentazione interna : parte della memoria assegnata a un processo non é utilizzata. 
una politica di assegnazione delle partizioni ai job.

Partizioni variabili
Una gestione un'pò flessibile, uno spazio libero contiguo abbastanza grande, si carica processo, con la creazione o terminazione di processi si creano dei buchi non contigui di grandezza variabile.
verificarsi una situazione in cui un nuovo processo deve essere creato, in totae ci sarebbe abbastanza memoria per caricalo, é la formula da molti frammenti non contigui: si ha frammentazione esterna, troppompiccoli per essere utilizzati 

Come affrontare la frammentazione esterna :
- Effettuare periodicamente una compattazione della memoria
- Utilizzare il disco come "deposito temporaneo" di processi effettuando lo swapping: lo swap out di un processo per fare spazio ad uno nuovo lo swap in queando si libera nuovamente dello spazio.

Processi a dimensione variabile
ci sono Strutture dati che possono crescere, conviene allocare fin dall'inizio più spazio di quanto richiesto inizialmente, si eccede anche quello, o c'è un nuco contiguo, oppure devo spostare il processo in uno spazio più grande, o ancora fare swap out.

Algoritmi di allocazione nello spazio con partizioni variabili

- First Fit : il primo abbastanza a partire dall'inizio della lista degli spazi liberi
- Next Fit : il primo grande abbastanza a partire dal punto della lista dove si era fermata l'ultima ricerca
- Best Fit : lo spazio che meglio si adatta alla dimensione del proceso, evita occupare spazi grandi che potrebbero servire dopo per allocare processi più grandi. crea rimanenze piccole per essere utilizzate
- Worst Fit : lo spazio che peggio si adatta alle dimensioni del processo, serve per lasciare spazi abbastanza grandi da essere utilizzabili

Algoritmo di allocazione : 
Esempio
sono presenti i seguenti spazi liberi : 
100K, 500K, 200K, 300K, 600K, come verrebbero allocati i seguenti processi : p1(212k),p2(417K),p3(112K),P4(426K)

First Fit: P1 in 500K (rimane 228K), P2 in 600K (rimane 183K), P3 in 288K (176K), p4 deve attendere

Best Fit: P1 in 300 K (rimane 88K), P2 in 500K (rimane 83K), P3 in 200K (rimane 88K), P4 in 600K (174K)

Worst Fit : P1 in 600k (rimane 388K), P2 in 500K (rimane 83K), P3 in 388K (rimane 276K), P4 deve attendere

Allocazione non contigua 
Schemi alternativi di allocazione dei processi, in memoria prevedono di poter suddividere l'immagine di un processo in porzioni : 
- dimensione qualsiasi 
- Dimensione predefinita

Segmentazione : l'immagine del processo è costituita da N spazi linerai di indirizzi, l'indirizzo logico é formato da una coppia
Paginazione : l'immagine del processo é costituita da N pagine di dimensione prefissata. l'indirizzo é in un unico spazio indirizzi , può essere composto in numero di pagina, offset
Vengono  allocati in memoria in posizioni non necessariamente contigue, l'utilizzazione delle memoria  : 
        - la segmentazione c'è frammentazione esterna, in misura minore rispetto all'allocazione contigua, faicle trovare posto per un segmento che per un intero processo 
        - la paginazione c'è fremmentazione interna, ma limitata a mezza pagina per processo .

la memoria virtuale 
il disco per contenere l'intera immagine del processo e caricare in RAM solo una parte dell'immagine del processo, quella effettivamente utile alla sua esecuzione nella fase attuale, RAM si può mantenere una porzione più grande del processo di quanta se ne tiene in cache.
lo spostamento da disco a ram e viceversa a blocchi.
permette di eseguire uno o più processi la cui dimensione, o la somma delle cui dimensioni, é maggiore di quelal dalla RAM.
parti dell'immagine di un processo possono, in un'alta percentutale delle esecuzioni del programma, non essere mai necessarie : 
        - ruotine che vengono chiamate raramente : funzionalità di un programma utilizzate poco di frequente dall'utente, ruotine di gestione di errori
        - Strutture Dati, allocate di grandi dimensioni ma, in molte esecuzioni, utilizzate soltato per una piccola parte 
la memoria virtuale su richiesta è sufficiente a caricare solo le pagine utilizzate.

La memoria virtuale 
é il fenomeno della località dei riferimenti alla memoria : per periodi significativamente lunghi, tipicamente un processo :
        - Accede ripetutamente ad indirizzi in un sottoinsieme delle sue pagine (working set)
        - Accede ripetutamente agli stessi indirizzi : Variabili usate ripetutamente, parti di codice usate ripetutamente
        - Accedere a indirizzi vicini a quelli usati poco prima : codice sequenziale, Spazzolare Array, per i loop si eseguono più volte istruzioni fra loro vicine.
        - non accede a quelli di altre pagine, che quindi possono non stare in memoria.
La località
Pagine servono ci baseremo sul passato, supponendo di non essere nei momenti di transizione, il cigno ner, l'autore Nassim Nicholas Taleb presente la storia di un tacchino nutrito dagli umani, supponiamo di misurare il suo benessere o difucia negli essere umani.
Fortuna nel rimpiazzamneto delle pagine non siamo come quel tacchino: se i momenti di transizione, della località sono davvero pochi, a quelli sopravviveremo, al costo di rimpiazzare un pò di pagine.

La memoria virtuale
é proprio la necessità di eseguire programmi che richiedono più spazio della RAM disponibile, Sistemi "primitivi" questo si realizzava permettendo ai programmatori di spezzare codice e dati di un programma in "Sezionni" chiamate overlay,
il sistema operativo forniva la possibilità di rimpiazzare un overlay con un altro durante l'esecuzione.
lo svantaggio di questo apprioccio è che la gestione degli overlay é a carico del programmatore

La tecnica di paginazione su richiesta, svolge in aumatico, in modo completamente trasparente per il programamtore.
un sistema multiprogrammato tali tacniche permettono anche di mantenere in memoria un insieme di processi che complessivamente occuperebbero più spazio della memoria RAM disponibile.
        1. L'immagine in memoria di ciascun processo viene suddivisa in blocchi di ugauale dimensione chiamati pagine.
        2. La memoria fisica viene suddivisa in frame della stessa dimensione delle pagine logiche
        3. Processo viene mantenuto una tabella delle pagine, che indica per ciascuna pagina dello spazio di indirizzi del processo se si trova o meno in memoria RAM, e in quele framme.
           Occorre inoltre tenere traccia della posizione delle pagine logiche su disco.
        4. PAginazione senza memoria virtuale tutte le pagine devono essere caricate in RAM, con memoria virtuale.

Esempio 
Lo spazio di indirizzi del processo P1 comprende 16 pagine logiche da 4Kbyte ciascuna (4K * 16 2^16 byte)
La RAM ha solo 8 frame  : la figura mostra una situazione in cui sono caricate in RAM le pagine logiche 0, 1, 2, 3, 4, 5, 9, 11 del processo rispettivamente nei frame 2, 1, 6, 0, 4, 3, 5, 7
La pagine logiche possono essere caricate in frame non consecuitivi, e in ordine sparso
traccia in una tabella delle pagine.

Traduzione da indirizzo logico a indirizzo fisico
Deve eseguire LA MMU per tradurre gli indirizzi logici (IL) in indirizzi fisici (IF).
l'operazione da fare sarebbe : 
  1. Calcolo numero di pagine logica (NP) e offset (o) : 
                NP = IL / DimPag; O = il % DimPag
        /*Quoziente e resto della divisione intera*/
   Quoziente e restp della divisione intera 
        DimPag * NP + O; con O < dimPag 
  2. if(TabPag[NP].Present == 0) then trap (page fault)
      else NF = TabPag[NP].frame
  3. Indirizzo fisico IF = indirizzo Frame NF + O = DimPag * Nf + o

Trattaemento dei page fault
Solo un sottoinsieme della pagine è presente in memoria, si può verificare un accesso ad una pagina non caricata :  in questo caso MMU genera una trap di tipo apge fault, la cui gestione é :
     1. Cerca un frame libero in RAM : se non c'è, si sceglie una pagina vittima
     2. il frame selezionata viene etichettato busy in modo che venga scelto di nuovo come vittima
     3. se necessario su disco
     4. si carica la pagina che ha causato il page fault da disco a RAM, mentre la pagina viene caricata, la CPU può essere data ad un altro processo;
     5. l'interruzione da disco dice che la pagina é caricata, si aggiorna la tabella delle apgine, e si rimette il processo pronto; quando girerà eseguirà di nuovo l'istruzione che ha causato il page fault.

Traduzione degli indirizzi 
non c'è bisogno di usare hw in grado di fare divisioni e moltiplicazioni se DimPag = 2^K; se supponiamo che il numero di bit dell'IL sia m e il numero di bit nell'indirizzo fisico sia Fault
gli m-k bit più significativi di IL e i K bit meno significativi sono quozionete e resto della divisione 2^K, e per ottenere 2^K * NF + O basta gistaporre i bit.
8196 / 4096 = 2, con resto 4, in binario é 
        
        001000000000100 /
           100000000000 =
                   0010
Resto 100
in questo caso la pagina  0010, vale a dire 2, é presente e si trova nel frame 110, vale a dire 6, allora : 

             100 * 
   1000000000000 =
 100000000000000 +
             100 =
 100000000000100

Trattamento dei page fault 
Un sottoinsieme della pagine é presente in memoria, si può verificare un accesso ad una pagina non caricata :  questo caso la MMU genera una trap di tipo page fault, la cui gestione é :
    1. Cerca un frame libero in RAM : se non c'è, si sceglie una pagina vittima
    2. il frame selezionato viene etichcettato busy in modo che non venga scelto di nuovo come vittima
    3. se necessario su disco 
    4. si carica la pagina che ha causato il page fault da disco a RAM; mentre la pagina viene (salvata) caricata, la CPU può essere fata ad un altro processo
    5. l'interruzione da disco dice che la pagina è caricata, si aggiorna la tabella della pagine, e si rimette il processo pronto; quando girerà eseguirà di nuovo l'istruzione che ha causato il page fault

Traferimento delle pagine da disco a RAM        
Viene creato il processo, viene allocato lo spazio per la sua immagine sulla baking store, poi le pagigne vengono caricate in RAM secondo necessità. le operazioni di swap-in delle pagine avvengono su richiesta durante l'esecuzione del processo, cioé in seguita ad un page fault
durante una fase di prepaging attivata dal sistema oeprativo prima di rendere running un processo. 

le operazioni di swap-out delle pagine avvengono quando si deve liberare spazio per nuove pagine, conviene che l'hardware fornisca traccia in un bit per ogni pagina, sono state effettivemnte modificate dall'utlimo caricamento,
al momento del rimpiazzamento copiare su disco la pagina rimpiazzata solo se il suo dirty bit vale 1.

Il rimpiazzamento delle pagine
Gestire una trap di tipo page fault il sistema oeprativo deve : 
        - scegliere un frame in cui caricare la pagina; uno libero, se c'è oppure uno che contiene una pagina che si spera vada bene rimpiazzare
        - leggere da disco la pagina mancante e caricarla nel frame scelto

l'algoritmo di rimpiazzamento che sceglie la pagian da ogni page fault deve cercare di minimizzare il numero  di page fault, ne sono stati considerati tanti
        - Ottimale 
        - Least Recently Used (LRU) 
        - Not Recently Used (NRU)
        - FIFO
        - seconda possibilità o dell'orologio

Rimpiazzamento delle pagine
le prestazioni dei diversi algoritmi di rimpiazzamneto si confrontano i numeri di page fault che si ottengono applicandoli a un insieme di stringhe di riferimenti alla memoria.
tale stringa di riferimenti, alla memoria, Stringa può essere data come  : 
        - lista di indirizzi generata deall'eseccuzione di un processo o lista di pagine logiche.
        - Eventualemnte corredati dall'indicazione del tipo di accesso

Solo processo o per processi diversim perché in un sistema multiprogramamto si possono usare due approcci al rimpiazzamento
        1. Locale --> ad ogni processo viene assegnato un numero di frame definito, quando P1 causa un page fault, la vittima per il rimpiazzamento può essere scelta solo tra le pagine di p1
        2. Globale --> la vittima per il rimpiazzamento può essere scelta fra tutte le pagine in memoria

il rimpiazzamento delle pagine
Ogni momento in memoria vi fosse l'intero working set (WS) di ogni processo, informalmente: l'insieme di pagine necessarire al processo in quella fase delal sua esecuzione, ricordiamo la località, nel tempo e nello spazio
quindi ci si basa sul passato, supponendo di non essere nei momenti di transizione, se davvero sono pochi , il costo é accettabile fissato un numero k di riferimenti da considerare, il working set del processo in un dato istante della sua esecuzione può essere definito come, l'insieme di pagine
utilizzate negli utenti k riferimenti alla memoria.

Una finestra temporale di ampiezza t utnia di tempo definendo il working set come l'insieme di pagine riferite nelle ultime t unità di tempo di esecuzione.

Algoritmo di rimpiazzamento
Richiede di conoscere i riferimenti futuri. una stringa r1,R2,R3,...,Rn di riferimenti a pagine logiche, le pagine vengono caricate finchè nono si riempe la RAM o il numero di frame assegnati al processo.
il primo riferimento rK per cui è necessario un rimpiazzamento viene scelta come vittima la pagina che verrà nuovamente usata più lontano nel futuro.
è ottimale, cioènon si può trovare un ccriterio che causi meno page fault. ma può essere usato come riferimento per misurare se ci possiamo acocntantare di un altro algoritmo

Algoritmo di rimpiazzamento LRU
viene scelta come vittima, la paginaa che è stata usata più lontano nel passato : 
come indicazionee di ciò che accadrà nel futuro, il principio di lcoalità temporale del resto porta a supporre che una pagina riferita nel passato recente ha più probabilità di essere nuovamente usata nel futuro vicino di una pagina riferita nel passato remoto

Algoritmo Not Recently Used
LRU é troppo pesante da realizzare in modo esatto, si utilizzano delle approssimazione con queello che "passa" l'hardware; in particolare due bit per ogni frame : 
   - R = bit di riferimento (diventa 1 quando la pagina viene letta/scritta)
   - M = bit di modifica (dirty bit, diventa 1 quando la pagina viene scritta)
    
      R  M 
      0  0    Classe 0
      0  1    Classe 1
      1  0    Classe 2
      1  1    Classe 3


R e M vengono impostati dall'hardware e azzerati dal S.O, l'algoritmo NRU il bit R viene azzerato, stato un accesso recente
si verifica page fault, se c'è bisogno di un rimpiazzamento, NRU sceglie in ordine crescente di classe.

Algoritmo FIFO e della seconda possibilità
le pagine che si trovano in memoria sono mantenute in una lista, ordinata in abse all'istante di caricamento in ram, al momento del rimpiazzamento viene scelta come vittima 
la pagina in testa alla lista.
buttata via la pagina presente da più tempo indipendentemente da quando si sta riferita l'ultima volta.
la seconda possibilità è una variabile che utilizza il bit R : la pagina in testa alla lista viene graziata se il suo R è 1; viene portata in fondoalal lista e il suo r azzerato
 e si considera la successiva.ù


Algoritmo della seconda possibilità o dell'orologio 
é una lieve semplificazione implementativa dell'algoritmo della seconda possibilità: si usa una lista circolare e anzichè portare in fondo alla lista la pagina non rimpiazzata,
si fa avanzare il puntatore. nuova pagina va inserita subito prima di quella puntata dal puntatore.
coincide con FIFO se le pagine hanno tutte R=1, se questo capita spesso, vuol dire che sono tutte molto usate e quindi non c'è da sperare di riuscire a tenere in RAM tutte le pagine che servono.
Altrimenti, una pagina graziata verrà ripresa in considerazione dopo un certo numero di page fault : 
        - continua ad essere usata abbastanza di frequente, probabilmente nel frattempo sarà stata usata,a vrà di nuovo R = 1 e verra graziata di nuovo
        - no, verrà scelta.
un numero di frame sufficiente per le pagine ustate di frequente, queste tenderanno a non essere usate.

il rpoblema del trashing 
l'overhead in termini di tempo dovuto alla paginazione può diventare enorme in determinate siturazioni :
 Thrashing -> la presenza contemporanea in memoria di n processi tali che la somma delle dimensioni dei loro working set eccede la dimensione della RAM
i sintomi di questo fenomeno sono :
     - un altissimo tasso di page fault
     - bassa utilizzazione della CPU
     - Alta utilizzazione del disco che svolge il ruolo di backing store.

l'effetto é rallentare l'esecuzione di tutti i processi, dato che il sistema spende gran parte del tempo a gestire i page fault,
la backing store diventa un collo di bottaglia.
passare per mandare avanti l'esecuzione di poche istruzioni di CPU.

Problemi del Thrashing
evitare il thrashing, oltre a cercare di mantenere in RAM solo il working set dei processi :
    - monitorare il tasso di pagedault
    - monitorare la dimensioni dei working set dei processi in memoria
    - Fare swap-out di uno o più processi, in modo da lasciare in memoria un insieme di processi tali che tutti i loro working set possano coesistere in memoria.


Trashing e livello di multiprogrammazione
Applicare il criterio : 
        "se l'utilizzazione della CPU é bassa, allora aumenta il livello di multiprogrammazione"
si arriva al thrashing, aumentare il livello di multiprogrammazione peggiora l'utilizzazione della CPU.

Algoritmi di rimpiazzamento basati sul working set
l'informazione sulle pagine che costituiscono il working set dei processi in memoria si può :
        - il possibile per evitare il thrashing e non dover fare swap out
        - accorgersi di doverlo fare

Definire quali pagine fanno parte del working set di un processo : 
        - si fissa un'ampiezza  t della finestra temporale 
        - mantiene traccia per ogni frame di un tempo di ultimo riferimento : 
                il bit R ad ogni riferimento, ad ogni timer interrupt :
                   - i bit R vengono azzerati 
                   - ma se il bit r di un frame era 1, viene copiato nel suo cmapo ultimo riferimento il tempo di CPU complessivamente utilizzato dal processo a cui appartiene

Pagina è nel WS :
      tempo virtuale auttuale --> tempo di virutale di ultimo riverimento < tabella
se is vuole mantener traccia al'intenor WS conviene mantenere l'elenco esplicito delle pagine nel PCB.
un page fault si può applicare l'algoritmo dell'orologio modificato in modo da creare di non rimpiazzare apgne contenuta nel working set
le pagine sono nel working set, allora se ne sceglie una a caso, con preferenza per quella che hanno il dirty bit a 0
   - Frequenza di page fault è elevata
   - spesso non si trovano pagiine non appartenenti al Ws
il thrashing è bene fare swap-out si un processo, dimminuendo il livello di multiprogrammazione
la scelta di t influenza la dimensione del ws: un valore troppo grande potrebbe classificare come parte del WS molte pagine che invece non sono più utili.

Polita locali e globali
Politica globale si può assegnare ad ogni processo un numero di frame variabile nel tmepo, tenendo conto della frequenza di page fault :
  Sale soopra A, é segno che il suo working set è più grande del numero di frame asseganti, per continuare a farlo girare bene bisogna assegnarglien altri
  si swap out in attesa di tempi migliori.
  scente sotto B, gli si possono portare via dei frame.

Il Page Daemon
Assicurare che nel momento in cui serve avere un frame da rimpiazzare esista qualche frame "pulito" é utile mantener un processo in backgorund, chiamato "paging deamon"
Chiamato "paging Daemon" che periodicamente venga attivato per controlalre la situazione dei frame in memoria.
Non ci sono sono frame disponibili, il daemon selezione una pagina utilizzando lo stesso algoritmo di rimpiazzamento usato dal page fault handler, e se la pagina non é
pulita richiede la sua scritta su disco.
la pagina selezionata dal paging deamon é un condidato ideale per un rimpiazzamento, ma non viene "buttata Via" : questo modo potrà essere recuperata nel caso sia
riferita prima di essere effettivamente rimpiazzata.

Pagine condivise 
Condivisione di pagine dati é uasta ad esempio per il codice, é usata anche quando un processo ne genera un altro con fork, tipicamente il nuovo processo fa exec poco dop, 
allora conviene non fare la copia subito di tutta l'immagine del processo. le pagine che uno dei due processi, dopo la fork, cerca di modificare.
    1. Pagine vengono etichette read-only
    2. tentativo di scriveri causa una trap
    3. la gestione di questa viene fatta la copia della pagina, in due pagine read-write
    4. Viene fatta ripartire l'istruzione che ha causata la trap.

Overhead
Spazio : 
     - ogni processo occorrre mantener una tabella delle pagine che può essere molto grande
     - si risolve la frammentazione esterna ma vi è frammentazione interna
Tempo : 
    - Context Switch occorre aggiornare le informazioni utilizzate dalla MMU per la traduzione degli indirizzi 
    - il trattamento dei page fault può far crescere di molto i tempi medi di accesso alla memoria.

Quando interviene il SO nella gestione della memoria con paginazione
Situazioni : 
    1. Creazione di un processo 
       determianre la dimensione del processo, allocare spazio per tale processo in backing store creare la page table.
    2. Cambiamento di stato di un processo Ready --> Running 
       Deve reimpostare la MMU per il nuovo processo, IL TLB deve essere invalidato 
    3. Quando si verifica un page fault
       determinare la pagina richiesta, sceglier una vitima da rimpiazzare, fare swap-out di tale pagina, fare swap in di quella richiesta
    4. Terminazione di un processo 
       Rilasciare page table, e i frame occupati dalle pagine del processo 