Il sistema operativo realizza un certo numero di nuove astrazioni: come ad esempio il processo

def di processo :  é un attività di elaborazione guidata da un programma, la sua velocità di esecuzione dipende da quanti processi condividono la stessa CPU e Memoria.
un processo é un attività di elaborazione su una cpu virtuale e una memoria virtuale grande abbastanza per contenere i dati e il codice del programma associato al processo. in questa interpretazione 
la CPU virutale e una memoria virtuale grande abbastanza per contenere i dati e il codice del programma associato al processo. in questa interpretazione al CPU virtuale funziona in modo intermittente,
dato che é in grado di potare davvero avanti la computazione solo quando ad essa corrispondono CPu e memoria vera.
un processo non coincide con un programma: in un dato momento ci possono essere 0,1,2,... processi che eseguono lo stesso programma,inoltre il programma di un processo può anche cambiare durante la 
vita di un processo.
il sistema operativo deve mantenere lo stato dell'elaborazione per goni processo, in questo caso inteso come dati in memoria e valori dei registi. nel caso di più processi che eseguono lo stesso
programma questo può essere condiviso, i dati no.

il termine pseudo-parallelismo va ad indicare che l'evoluzione é apparentemente parallelo, con uan singola unità di elaborazione. é effettivamente parallela fino al grado n, oltre a quello, m(<n)
processi/threads si dividono le n unità fornite dall'hw.
a. Multiprogrammazione di 4 programmi 
b. Modello concenttuale di 4 processi sequenziali indipendenti
c. solo un processo é running in ogni instante (o solo n, con n CPU)

in un sistema multiprogrammato, non si possono in generale dare garanzie sulla velocità dei processi basandosi su una stima del tempo di CPU necessario ad eseguire parti del codice del processo :
ne quella assoluta : non possiamo garantire che un processo arrivi ad un punto x del suo codice in un dato tempo (Assoluto)
ne quella relativa : non possiamo garantire che il processo a raggiungerà un certo punto x della sua esecuzione prima che il processo b raggiunga il punto y della sua esecuzione.

questo é dovuto da due motivi : 
1. non si puà prevedere sempre quali parti del codice verranno eseguite e quinti quanto tempo di CPU serve per arrivare a un dato punto.
2. il processo sta eseguendo, può arrivare un interruzione e la cpu può essere assegnata ad un altro processo.

Garantisce la velocità assoluta possono essere fornite attraverso appositi meccanismi solo dai sistemi operativi real-time,  
  - i vincoli possono essere di hard real-time : 
       ad esempio nel caso di processi per il controllo di impianti, veicoli: non soddisfarli ha un costo non accettabile)
  - Soft real-time :  é accettabile non soddisfarli ogni tantno, il costo di non soddisfarli cresce, anche non linearmnete, con il numero di volte in cui non li si soddisfa.

in altri sistemi, la velcoità effettiva dei processi dipende dal criterio di assegnazione della cpu ai processi; possiamo solo aspettarci che su scala lunga i processi vadano avanti
con velocità simile, ma senza garanzie.

troviamo solamente garanzia sulla velocità relativa, la quale possono essere ottenute con meccanismi espliciti di sincronizzazione fra processi, che verrano introdotti più avanti.

Creazione di processi
quando un utente apre una finestra "terminale" o si collega in remoto, viene creato un nuovo processo, un interprete di comandi. l'interprete si chiede di eseguire un programma, l'interprete crea un
nuovo processo che metterà il programma in questione. intatno l'interprete di comandi si metterà in attesa della terminazione di tale processo: qunado questa si verifica, il processo "padre" riprende 
la sua esecuzione, chiedendo un nuovo comando all'utente.
dal file manager di una interfaccia grafica, cliccando sull'icona di un file, tipicamente viene fatto partire un processo che esegue un programma associato al tipo di file.

Terminazione dei processi
la terminazione di un processo pià essere causata da diverse circostanze: 
1. il programma da eseguire ha concluso correttamente la sua esecuzione
2. si é verificata una condizione di errore rilevata dal programma, e il programma stesso decide di termianre
3. si é verificata una condizione di errore imprevista, che ha causato un trap, gestione del S.O terminando il processo
4. il processo é stato "terminato" da un altro processo (Attraverso una opportuna System call)


Stati di un processo 
Attivo : la sua esecuzoine puà proseguire
Waiting (o bloccato) : é in attesa di ricevere in input da un dispositivo ("read in Unix"), in attesa della terminazione di un processo figlio (Wait o waitpid), o in attesa che vengano immmessi dati 
in una pipe (vale a dire ancora in lettura)

                                                  Processo Attivo 
   Conclusione I/O o Evento Avvenuto               \           /          Richiesta I/O o Attesa Evento 
    (Interrupt o chiamata di sistema da             \         /               (Chiamata di sistema)
     da parte di un altro processo                    Waiting 

Processo Attivo
La sua esecuzione può proseguire 
1. Running :  se ha anche una CPU, quindi é effittivamente in esecuzione 
2. Ready : Pronto, ma la CPU é usata da qualche altro processo 

                    Scheduler, Dispatcher

          Ready <-----------------------------> Running
             ^                                 ^
              \     (Timer) interrupt         /          1 Conclusione I\O o Evento Avvenuto
               \          handler            /  2        2 Richiesta I\O o Attesa evento
                \                           /
                 ------- Waiting----------

Scheduler e Dispatcher
Scheduler  --> il componente del sistema operativo che si occupa di scegliere quale processo deve diventare running tra tutti quelli attivi (viene attuata in base ad una politca di scheduling)
Dispatcher --> il componente del sistema operativo che attua il context switch (Caricando nei registri lo "Stato del processo scelto dallo scheduler per diventare running, e salvando lo stato del processo che smette di essere running; "Stato" inteso come valori dei registri.

un Esempio di separazione fra politiche e meccanismi, una buona caratteristica strutturale dei sistemi operativi che ne facilità la portabilità e la flessibilità. qui il dispatcher realizza un meccanismo; lo scheduler una politica che utilizza il meccanismo.
Seperazione posso più facilmente :  
    - Riusare un meccanismo per politiche diverse
    - Riusare una stessa politica su meccanismi diversi.

Nuovo : durante la craezione ( potrebbe essere tento in anticamera prima mdi allocargli risorse, per limitare il livello di muiltiprogrammazione)
Treminato : il processo é termianto ma il S.O. ne tiene ancora traccia
In Corso : il processo é pronto per essere eseguito, in esecuzione o bloccato in attesa di un evento

Esempio passaggi di stato di un processo p 
Eventi                               Stati del processo P dopo L'evento
1. creazione                           New; Ready
2. Scelto dallo Scheduler              Running
3. P Chiama Read ()                    Waiting 
4. Interrupt  (Concluso I/O)           Ready
5. P scelto dallo scheduler            Running
6. P esegue exit ()                    Terminated


            New --1--> Ready  <-2-----5->    Running  
                          ^                     /    \
                        4   \                 / 3     \------>  Running
                                Wainting
PCb
Il sistema Opeartivo mantiene una struttura, chiamata Process Control Block (PCB) per ogni processo nel sistema. la tabella dei processi contrine l'insieme dei PCB di tutti i processi presenti nel sistema.

Lo stato dei registri viene salvato nel PCB e ripristinato in occasione context swtich (commutazione il contesto, la CPU passa da un processo a un altro) 

Code di processi 
I vari PCB possono essere nodi di lise che costituiscono la coda dei processi pronti (ready queue) ele code di attesa di altri eventi 

l'introduzione dell'astrazione dei "processi" é stata inizialmente motivata dalla necessità di utilizzare al meglio le risorse disponibili, in particolare la CPU
L'utente o gli utenti fanno partire : un elaboratore di testi, un browser, un lettore multimediale etc: 
   - Applicazioni progettata indipendentemente
   - Lanciate indipendetemente
   - non devono condividere codice ne dati
   - vanno mandate avanti in (pseudo)parallelo

i processisono tra loro in competizione per l'accesso a un insieme di risorse condivise, il compito del sistema operativo é assicurare la non interferenza tra processi che si trovano per caso ad utilizzare le stesse risorse come ad esempio (hardware : CPU, memoria, dispositivi) del sistema di elaborazione.

un insieme di processi può anche cooperare per raggiungere un obbiettivo : 
 - in questo caso tipicamente condivideranno per scelta : 
     - programma
     - Dati
     - file aperti
     - hardware

il sistema operativo dovrà fornire dei meccanismi per permettere ai processori cooperanti di comunicare e sincornizzarsi, il vantaggio --> permettere uno stile di programmazione modulare di attività in parte indipendenti; quando per potrane avanti una é  necessario attendere un evento. questo si chiama una primitiva bloccante che sospende, se necessario, l'esecuzione fino al veririficarsi di un determinato evento.
quando si arriva all'istruzione successiva, l'evento si é verificato, nel frattempo il S.o potrà mandare avanti gli altri processi, preoccupandosi di riportare pronti quelli sospesi, quando l'evento occorre.

nel caso di attività cooperanbti questo però é più costoso del necessario in termini di context switch : dato che alcune risorse §(tipicamente di memoria) sono condivise, il contesto ptorebbe non dover cambiare molto.
       questo ha portato all'introduzione dei threads.


Threads 
in un processo, più flussi di controllo (threads) che condividono la stessa memoria ed eseguono parti diverse del codice, tre precessi, ciascuno con un thread, un processo con tre threads
la cpu viene assegnata dallo scheduling ai vari thread, di un dato processo accedono alla medesima area di memoria.
programmazione con primitive bloccati : Server Web che riceve richieste, gestire una richiesta può richiedere lettura di informazioni del disco, non sempre se le pagine più richieste le teniamo in una cache in memoria.

1. While(true)
    {
        leggi richiesta;
        esegui richiesta (con lettura bloccate, se da disco);
} \\ Errore ma é inefficiente!
mentre avviene la lettura, vorremmo potre esamire altre richieste

perché sono utili i threads
possimao avere due soluzioni :
1. 
la richiesta di lettura non bloccante e thread singolo : 
    a. attendi o rileva il prossimo evento  
    b. se è la terminazione di una lettura, rispondi alla richiesta corrispondente
    c. se è una nuova richiesta, soddisfala se la pagina è in memoria, altrimenti richiedi la lettura con una operazione non bloccante
bisogna tener traccia delle richieste in corso di trattamento
2. 
primitive bloccanti e thread multipli :
    a. leggi richiesta
    b. crea o risveglia un thread per gestirla, e il codice del thread
    c. effettua la lettura (bloccante se da disco)
    d. risponde alla richiesta
    per ogni richiesta in corso di trattamento, c'è un thread :  è la gestione dei thread a tenere traccia per noi di queste richieste
--------------------------------------------------------------------------------------------------------------------------------------
| Per process items                                                  | Per Thread items                                              |
| Address Space                                                      | Program counter                                               |
| Global Variables                                                   | Registers                                                     |
| Open Files                                                         | Stack                                                         |
| Child processes                                                    | State                                                         |
| Peding alarms                                                      |                                                               |
| Signals and signal handlers                                        |                                                               |
| Accounting information                                             |                                                               |
--------------------------------------------------------------------------------------------------------------------------------------

Thread ha nun suo stato : Ready, running, waiting), i suoi registri di cPU incluso il program counter, Stack pointer, ecc.., il suo Stack
lo spazio di indirizzamento é condiviso, non vi é protezione fra thread, perchè sono progettati per cooperare e condividere risorse.
Errori di programmazioni possono avere effetti più gravi ad essere più difficili da scoprire rispetto al caso di thread singolo, i thread si
potrebbero alterare i dati 

Utilizzo threads 
- parallelismo all'interno di una singola applicazione [come per applicazione con processi multipli]
- Sovrapposizione (anche se su un processo singolo) di I/O e computazione per i thread di una singola applicazione
  [Com per applicazione con processi multipli]
- Condivisione di risorse fra attività cooperanti in una applicazione [ più semplice rispetto ad applicazione con processi multipli]
- Creazione di un nuovo thread, switch fra thread [meno costoso rispetto 1a processi]

Thread a livello utente e thread a livello kernel 
i thread possono essere implementati  : 
        1. a livello utente
            nel caso il S.O. non é conoscenza dell'esistenza dei thread, che vengono gesitti completamente in modalità Utente (cioé non 
            si richiede l'intervento del sistema operativo epr creare, terminare, schedulare per l'esecuzione, sospendere o risvegliare threads)
            il sistema di gestione dei thread é costituito  da una libreria di funzioni .
        2. a livello kernel 
            lo shceduler di gestione della CPU la assegnata ai processi, il sistema di gestione, per ogni processo P che usa thread multipli,
            all'interno dello spazio di indirizzi di P mantiene una tabella dei thread con il loror stato, ed assegna il tempo di CPU concesso a P
            ai suoi thread pronti.

Thread a livello utente : 
Vantaggi 